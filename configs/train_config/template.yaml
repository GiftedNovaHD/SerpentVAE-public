# Training configuration
dataset_path:
dataset_name:
train_epochs:

# Model configuration
hidden_dim:
concept_dim:
vocab_size: 129280
dist_desired_std:
num_encoder_layers:
num_decoder_layers:
mamba_state_dim:
mamba_conv_length:
mamba_expand:
mlp_inner_dim:
confidence_inner_dim:
segment_pred_inner_dim:
share_input_embeddings: true
tie_embeddings: true
residual_in_fp32: false
device: "cuda"
dtype: "fp16"
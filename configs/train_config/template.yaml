# Training configuration
dataset_path:
dataset_name:
train_epochs:
eval_freq:
model_save_folder_path:
metrics_save_folder_path:
learning_rate:
max_seq_len:
batch_size:
seed: 6969

# Model configuration
hidden_dim:
concept_dim:
vocab_size: 129280
dist_desired_std:
num_encoder_layers:
num_decoder_layers:
mamba_state_dim:
mamba_conv_length:
mamba_expand:
mlp_inner_dim:
confidence_inner_dim:
segment_pred_inner_dim:
num_qnet_layers:
qnet_conv_length:
qnet_mamba_expand:
qnet_mlp_inner_dim:
qnet_mamba_state_dim:
share_input_embeddings: true
tie_embeddings: true
residual_in_fp32: false
device: "cuda"
dtype: "fp32"